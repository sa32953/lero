{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine :  Problem 1\n",
    "## SVM with SCIKIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "These exercises are based on the Stanford Machine Learning Course [CS229](http://cs229.stanford.edu) of Andrew Ng. The environment of the exercise have been tuned to the theory content taught at Ravensburg Weingarten University.\n",
    "\n",
    "We are using the Python programming language. If you don't know Python or if you would like to refresh your memory, take a look at the [Python tutorial](http://docs.python.org/tut/).\n",
    "We will mostly work with NumPy, the fundamental package for scientific computing in Python. Please read the [NumPy quickstart tutorial](https://numpy.org/devdocs/user/quickstart.html). In addition, the documention of MatPlotLib and Scipy lib can be found here: .[MatplotLib](https://matplotlib.org/). [Scipy](https://docs.scipy.org/doc/scipy/reference/tutorial/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset : \n",
    "\n",
    "In the first half of this exercise, you will be using support vector machines\n",
    "(SVMs) with example of linearly seperable 2D datasets. Experimenting with these datasets\n",
    "will help you gain an intuition of how SVMs work. In the second half, you will be using a non-linear 2D dataset and how to use a Gaussian\n",
    "kernel with SVMs.\n",
    "\n",
    "### 1.A Visualize the linear separable dataset\n",
    "\n",
    "We will begin by with a 2D example dataset which can be separated by a\n",
    "linear boundary. In this dataset, the positions of the positive examples (indicated with +) and the\n",
    "negative examples (indicated with o) suggest a natural separation indicated by the gap. However, notice that there is an outlier positive example + on the far left at about (0.1, 4.1). As part of this exercise, you will also see how this outlier affects the SVM decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# for plotting grayscale\n",
    "from PIL import Image\n",
    "\n",
    "# Dataframe management\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the linear data\n",
    "df = pd.read_csv('''Load Data''')\n",
    "\n",
    "# Extract the data present in frame heads\n",
    "X = df[['x','y']].values \n",
    "y = df['label'].values\n",
    "\n",
    "m = '''Size of dataset'''\n",
    "\n",
    "print('There are total of {} points in dataset'.format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting is done using a python library 'matplotlib'. See documention of the library at https://matplotlib.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X,y):\n",
    "\n",
    "    '''code here'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.B SVM theory and implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector machine solves a constrained optimization problem to find this optimal hyperplane. Given to us the two classes that coulb be separated by a hyperplane. There may exist multiple hyperplanes diving the classes. \n",
    "\n",
    "**But which one is the best ?**\n",
    "\n",
    "The optimum hyperplane would be the one evenly distributed wrt the margin between the two classes. Let us try to understand this with below shown image.\n",
    "\n",
    "<img src='./graphic/1.png' width='650' height='650'>\n",
    "\n",
    "Here, the solid line is the hyperplane. The two dashed lines are marked the closest point(s) of each given class. The margin on side side can be denoted as: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "margin = \\frac{w^T}{\\lVert w \\rVert} (x_j - x_i)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In other words this can be written as: $$margin=\\frac{2}{\\lVert w \\rVert}$$\n",
    "\n",
    "The objective is here to maximize this margin.\n",
    "This problem can be moulded and can be written in form of a minimization optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_{w,b}\\quad & \\lVert w \\rVert^2  \\\\\n",
    "\\text{s.t.}\\quad & y_i(w^Tx_i + b) \\geq 1\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This can be easily solved with the Scikit library. The constrained optimization problem can be combined and written as **Dual Optimization problem**. One could refer to the theory part to get clear about problems' solution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint: You may want to look up into https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Code Here''''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define a classification line, we consider that the probabilty of the Output Class (y) of a given Input Point (X') is 1/2. We say that Class of a given data point is determined by \n",
    "\n",
    "$$y* = sign(kernel(X'))$$. \n",
    "\n",
    "With this consideration we can say that equation of line can be determined by follwing:\n",
    "\n",
    "$$kernel(X') = 0$$ \n",
    "\n",
    "Expanding the above equation we get:\n",
    "\n",
    "$$\n",
    "w_0* (x) + w_1* (y) + b = 0\n",
    "$$\n",
    "\n",
    "Since we already identitifed the **max** and **min** points two plot the line, we can compute the y-axis co-ordinate by following equation:\n",
    "\n",
    "$$\n",
    "y = \\frac{-(w_0x + b)}{w_1} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up two points that can be used to plot a line\n",
    "x_min, x_max = min(X[:, 0]), max(X[:, 0])\n",
    "plot_x = np.array([x_min, x_max])\n",
    "\n",
    "# Compute the other axis value based on learned weights\n",
    "plot_y = '''Complete here'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X,y)\n",
    "plt.plot(plot_x, plot_y, '-b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.C Non- Linear Dataset\n",
    "\n",
    "This part of the notebook uses a Non-Linear dataset for SVM problem. The Scikit library offers a set of datasets as toy problems which can be used to implement various concepts. If this sounds interesting to you then feel free to look here what's on offer : https://scikit-learn.org/stable/datasets/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "circle_X, circle_y = datasets.make_circles(n_samples=300, noise=0.075)\n",
    "\n",
    "def plot_circle(circle_X, circle_y):\n",
    "    \n",
    "    '''Code Here'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_circle(circle_X, circle_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels: \n",
    "\n",
    "Kernels are set of mathematical algorithm functions that are used in SVMs. Their job is to take the input data and transform it into a required form (can be incorporated well in the Optimization Equation). \n",
    "\n",
    "We saw above the **Linear Kernel**.\n",
    "\n",
    "Linear kernel functions (or the dot product) are faster than most of the others and you have fewer parameters to optimize. Here's the function that defines the linear kernel:\n",
    "\n",
    "$$\n",
    "\\phi(x)=w^TX+b\n",
    "$$\n",
    "\n",
    "Here in this equation, w is the weight vector that you want to minimize, X is the data that you're trying to classify, and b is the linear coefficient estimated from the training data.\n",
    "\n",
    "**Using the same Kernel for a non-linear dataset as above doesn't make much sense. There are few more options..**\n",
    "\n",
    "such as Polynomial Kernel, Sigmoid Kernel, Gaussian Radial Basis Function Kernel (known as RBF).\n",
    "\n",
    "$$\n",
    "RBF = k(x,y) = exp(-\\gamma \\lVert x_j-x_i \\rVert^2)\n",
    "$$\n",
    "\n",
    "It is a general-purpose kernel; used when there is no prior knowledge about the data. Don't confuse it with the **Gaussian Kernel**. We will be working with that in the next problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Code here'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary for a non-linear SVM problem\n",
    "def plot_decision(model, points):\n",
    "    \n",
    "    '''Code here'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision(nonlinear_clf, circle_X)\n",
    "plot_circle(circle_X, circle_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What can you do to further contribute in this notebook ?\n",
    "\n",
    "1. Try the SVM fitting with different kernels and different values of C.\n",
    "2. Try to find the accuracy of learned model. (Hint: You can do that by Cross Validtion using sklearn modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
